import sys

sys.path.append("../..")

import time
import streamlit as st
from torchblocks.tasks.uie import UIEPredictor

MODEL_CLASSES = {
    "UIE": "uie_base_pytorch",
    "UIE-MEDICAL": "uie_medical_base_pytorch",
    "UIE-MEDICAL-FINETUNED": "checkpoint/uie_medical",
}


@st.cache(hash_funcs={UIEPredictor: id})
def load_ie(model_name_or_path, schema, prob, max_seq_len, device="cpu", split_sentence=False):
    return UIEPredictor(model_name_or_path=model_name_or_path, schema=schema, position_prob=prob,
                        max_seq_len=max_seq_len, device=device, split_sentence=split_sentence)


# è®¾ç½®ç½‘é¡µä¿¡æ¯ 
st.set_page_config(page_title="UIE DEMO", page_icon="ğŸš€", layout="wide")

# st.title('UIE DEMO')
html_tmp = """
    <div>
    <h1 style="text-align:center;">UIEå‘½åå®ä½“è¯†åˆ«</h1>
    </div>
"""
st.markdown(html_tmp, unsafe_allow_html=True)
st.markdown('---')

st.subheader("ğŸ”¨å®šåˆ¶SCHEMA")
if candidate := st.checkbox('å€™é€‰å®ä½“ç±»å‹'):
    schema_options = st.multiselect('é€‰æ‹©é¢„å®šä¹‰çš„å®ä½“ç±»å‹',
                                    ["æ—¶é—´", "åœ°ç‚¹", "äººç‰©", "ç–¾ç—…", "ç—‡çŠ¶ã€ä¸´åºŠè¡¨ç°", "èº«ä½“ç‰©è´¨å’Œèº«ä½“éƒ¨ä½", "è¯ç‰©", 
                                     "æ£€æŸ¥ã€æ²»ç–—æˆ–é¢„é˜²ç¨‹åº", "éƒ¨é—¨ç§‘å®¤", "åŒ»å­¦æ£€éªŒé¡¹ç›®", "å¾®ç”Ÿç‰©", "æ£€æŸ¥è®¾å¤‡å’Œæ²»ç–—è®¾å¤‡"], None)
else:
    schema_options = None
schema = st.text_area("è¯·è¾“å…¥æŠ½å–ä»»åŠ¡çš„å®ä½“ç±»å‹ï¼ˆä½¿ç”¨ç©ºæ ¼åˆ†éš”ï¼‰ï¼š")
schema = (" ".join(schema_options) + " " + schema) if schema_options is not None else schema

st.subheader("ğŸ“–è¾“å…¥æ–‡æœ¬")
text = st.text_area("è¯·è¾“å…¥å¾…æŠ½å–çš„å¥å­ï¼š")

html_tmp = """
    <div>
    <h2 style="text-align:center;">é…ç½®å‚æ•°</h2>
    </div>
"""
st.sidebar.markdown(html_tmp, unsafe_allow_html=True)

# prob = st.sidebar.number_input('é˜ˆå€¼', 0.0, 1.0, 0.5)
st.sidebar.markdown('---')

model_type = st.sidebar.radio(
    "é¢„è®­ç»ƒæ¨¡å‹",
    ("UIE", "UIE-Medical", "UIE-Medical-Finetuned"),
)

st.sidebar.markdown('---')

max_seq_len = st.sidebar.number_input('å¥å­æœ€å¤§é•¿åº¦', 0, 512, 512)
st.sidebar.markdown('---')
prob = st.sidebar.slider("é˜ˆå€¼", min_value=0.0, max_value=1.0, value=0.5, step=0.01)

st.sidebar.markdown('---')
split = st.sidebar.checkbox('æˆªæ–­å¥å­')
gpu = st.sidebar.checkbox('ä½¿ç”¨GPU')
plot = st.sidebar.checkbox('æ˜¾ç¤ºå®ä½“æ ‡ç­¾åˆ†å¸ƒ')

schema = schema.split(' ')
device = "gpu" if gpu else "cpu"
ie = load_ie(MODEL_CLASSES[model_type], schema, prob, max_seq_len, device, split)

if st.button('è¿è¡ŒğŸš€') & (text != ''):
    text = text.split('\n')
    start = time.time()
    rlt = ie(text)
    running_time = time.time() - start
    st.text(f"Runtime for UIE: {running_time}")
    st.json(rlt)
    st.stop()
